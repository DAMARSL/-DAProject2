# -*- coding: utf-8 -*-
"""Untitled21.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q2j8yMH4nEGDNenGCOFthZjjClPZhJvZ
"""

import pandas as pd
import numpy as np

df=pd.read_excel("/content/Telco_customer_churn.xlsx")

df.head(10)

df.isnull().sum() #Boş değer yok

df.info()

df['Total Charges'] = pd.to_numeric(df['Total Charges'], errors='coerce')

import seaborn as sns
import matplotlib.pyplot as plt

# Sayısal sütunları seçin
numerical_columns = df.select_dtypes(include=['float64', 'int64'])

# Pearson korelasyon matrisini hesaplayın
correlation_matrix = numerical_columns.corr(method='pearson')

# Korelasyon matrisini yazdırın
print(correlation_matrix)

# Korelasyon matrisini bir heatmap olarak görselleştirin
plt.figure(figsize=(12, 10))  # Heatmap'in boyutunu ayarlayın
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)

# Başlık ve etiketler ekleyin
plt.title('Pearson Korelasyon Matriksi')
plt.show()

df_drop = df.drop(["CustomerID", "State", "Gender", "Count", "Zip Code", "Lat Long", "Churn Reason", "Latitude", "Longitude", "Country", "Churn Reason"], axis=1, inplace=False)
# CustomerID is changed to Customer ID based on the Excel File. inplace is changed to False, so it will return a copy of dataframe.
df_drop

df=df_drop

df.describe() ## Churn Value değerine baktığında %26'lık bir churn olduğunu görüyoruz. Bu da bize dengesi bir veri kümesi olabilir miyi düşündürüyor?

# Select object (categorical) columns
object_cols = df.select_dtypes(include=['object']).columns

# Apply one-hot encoding to the selected columns
df_encoded = pd.get_dummies(df, columns=object_cols, drop_first=True)

print(df_encoded)

# Korelasyon matrisi oluştur
corr_matrix = df_encoded.corr()

# Sadece "Churn" ile olan korelasyonları al
churn_corr = corr_matrix["Churn Value"].drop("Churn Value")

# Threshold uygula (örneğin |0.1| üstü korelasyonları al)
threshold = 0.1
filtered_corr = churn_corr[abs(churn_corr) > threshold]

# Sıralama
filtered_corr = filtered_corr.sort_values(ascending=False)

# Görselleştirme
plt.figure(figsize=(6, len(filtered_corr) * 0.4))
sns.heatmap(filtered_corr.to_frame(), annot=True, cmap="coolwarm", vmin=-1, vmax=1)
plt.title("Churn Value ile Korelasyonu Yüksek Özellikler (|r| > 0.1)")
plt.show()

X = df_encoded[["Churn Score", "CLTV", "Internet Service_Fiber optic", "Payment Method_Electronic check", "Monthly Charges", "Paperless Billing_Yes", "Tech Support_No internet service", "Device Protection_No internet service", "Internet Service_No",
   "Streaming TV_No internet service", "Online Backup_No internet service", "Online Security_No internet service", "Streaming Movies_No internet service", "Dependents_Yes", "Contract_Two year", "Tenure Months"]]

X = df_encoded[["Internet Service_Fiber optic", "Payment Method_Electronic check", "Monthly Charges", "Paperless Billing_Yes", "Tech Support_No internet service", "Device Protection_No internet service", "Internet Service_No",
   "Streaming TV_No internet service", "Online Backup_No internet service", "Online Security_No internet service", "Streaming Movies_No internet service", "Dependents_Yes", "Contract_Two year", "Tenure Months"]]

y=df_encoded["Churn Value"]

!pip install imbalanced-learn
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from imblearn.combine import SMOTEENN

# ... (Your existing code to create df_encoded and X) ...

# Create an imputer to replace NaN values with the mean of the column
imputer = SimpleImputer(strategy='mean')

# Fit the imputer on your feature data (X) and transform it
X_imputed = imputer.fit_transform(X)

# Now use the imputed data with SMOTEENN
sm = SMOTEENN(random_state=0)
X_resampled, y_resampled = sm.fit_resample(X_imputed, y)

# train test split
from sklearn.model_selection import train_test_split # Import the train_test_split function
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2 ,random_state=0)
# model training
from sklearn.ensemble import RandomForestClassifier # Import the RandomForestClassifier
clf = RandomForestClassifier(n_estimators=100, random_state=0)
clf.fit(X_train, y_train)

# model evaluation
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score # Import necessary functions
y_pred = clf.predict(X_test)
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nAccuracy:", accuracy_score(y_test, y_pred))

from sklearn.model_selection import cross_val_score

cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')

print(f"CV Mean Accuracy: {cv_scores.mean():.4f}")
print(f"CV Std Deviation : {cv_scores.std():.4f}")

import pandas as pd
import matplotlib.pyplot as plt

# Feature importances
importances = clf.feature_importances_
# Get feature names from the original DataFrame (X) before SMOTEENN
features = X.columns

# DataFrame oluştur
feat_imp_df = pd.DataFrame({
    'Feature': features,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

# En önemli 15 özelliği görselleştir
plt.figure(figsize=(10, 6))
plt.barh(feat_imp_df['Feature'][:15][::-1], feat_imp_df['Importance'][:15][::-1])
plt.xlabel("Önemi")
plt.title("Random Forest - En Önemli Özellikler")
plt.tight_layout()
plt.show()

# Modeli kaydedelim
import pickle
with open('random_forest_model.pkl', 'wb') as f:
    pickle.dump(clf, f)

print("Model başarıyla kaydedildi!")

!pip install streamlit

import streamlit as st
import pandas as pd
import pickle

# Başlık
st.title("Telecom Churn Prediction")

# Kullanıcıdan veri almak için widget'lar

# Categorical features
internet_service = st.selectbox(
    "Internet Service", ["No", "DSL", "Fiber optic"], index=2
)

payment_method = st.selectbox(
    "Payment Method", ["Electronic check", "Mailed check", "Bank transfer (automatic)", "Credit card (automatic)"], index=0
)

# Numerical features
monthly_charges = st.number_input("Monthly Charges", min_value=0, max_value=200, value=70)

paperless_billing = st.radio(
    "Paperless Billing", ["Yes", "No"], index=0
)

tech_support = st.radio(
    "Tech Support", ["Yes", "No", "No internet service"], index=2
)

device_protection = st.radio(
    "Device Protection", ["Yes", "No", "No internet service"], index=2
)

streaming_tv = st.radio(
    "Streaming TV", ["Yes", "No", "No internet service"], index=2
)

online_backup = st.radio(
    "Online Backup", ["Yes", "No", "No internet service"], index=2
)

online_security = st.radio(
    "Online Security", ["Yes", "No", "No internet service"], index=2
)

streaming_movies = st.radio(
    "Streaming Movies", ["Yes", "No", "No internet service"], index=2
)

dependents = st.radio("Dependents", ["Yes", "No"], index=0)

contract = st.selectbox(
    "Contract", ["Month-to-month", "One year", "Two year"], index=2
)

tenure_months = st.number_input("Tenure (Months)", min_value=0, max_value=100, value=10)

# Kullanıcıdan alınan verileri bir DataFrame'e dönüştürme
user_data = {
    "Internet Service_Fiber optic": 1 if internet_service == "Fiber optic" else 0,
    "Payment Method_Electronic check": 1 if payment_method == "Electronic check" else 0,
    "Monthly Charges": monthly_charges,
    "Paperless Billing_Yes": 1 if paperless_billing == "Yes" else 0,
    "Tech Support_No internet service": 1 if tech_support == "No internet service" else 0,
    "Device Protection_No internet service": 1 if device_protection == "No internet service" else 0,
    "Internet Service_No": 1 if internet_service == "No" else 0,
    "Streaming TV_No internet service": 1 if streaming_tv == "No internet service" else 0,
    "Online Backup_No internet service": 1 if online_backup == "No internet service" else 0,
    "Online Security_No internet service": 1 if online_security == "No internet service" else 0,
    "Streaming Movies_No internet service": 1 if streaming_movies == "No internet service" else 0,
    "Dependents_Yes": 1 if dependents == "Yes" else 0,
    "Contract_Two year": 1 if contract == "Two year" else 0,
    "Tenure Months": tenure_months
}

# Verileri DataFrame'e dönüştürme
user_df = pd.DataFrame([user_data])

# Modeli yükleme
with open('random_forest_model.pkl', 'rb') as model_file:
    model = pickle.load(model_file)

# Tahmin yapma
prediction = clf.predict(user_df)

# Tahminin sonucu
if prediction[0] == 0:
    st.subheader("Customer will NOT churn.")
else:
    st.subheader("Customer will churn.")

